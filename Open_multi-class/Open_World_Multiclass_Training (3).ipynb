{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gbuG5MGNnRy",
        "outputId": "377ba503-e666-44f8-b048-fa0576491c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d80wFt6oNYjZ"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# library import\n",
        "# =========================================\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz-taK1rNYjb",
        "outputId": "48fe3283-ff61-42d9-97bf-7fda822f7f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data loaded successfully!\n",
            "X_train: (16500, 25) | y_train: (16500,)\n",
            "X_test : (5500, 25)  | y_test : (5500,)\n",
            "\n",
            "ðŸ“Š Train data distribution:\n",
            "  - Monitored (0~94): 14250 samples\n",
            "  - Unmonitored (-1): 2250 samples\n",
            "\n",
            "ðŸ“Š Test data distribution:\n",
            "  - Monitored (0~94): 4750 samples\n",
            "  - Unmonitored (-1): 750 samples\n",
            "Check for labels: [-1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
            " 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34.\n",
            " 35. 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52.\n",
            " 53. 54. 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 68. 69. 70.\n",
            " 71. 72. 73. 74. 75. 76. 77. 78. 79. 80. 81. 82. 83. 84. 85. 86. 87. 88.\n",
            " 89. 90. 91. 92. 93. 94.]\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------\n",
        "# 1. data load\n",
        "# -----------------------------------------------------\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/ML_Dataset\"\n",
        "\n",
        "# Multi-class data\n",
        "X_train = np.load(f\"{BASE_PATH}/X_train_mc.npy\")\n",
        "X_test  = np.load(f\"{BASE_PATH}/X_test_mc.npy\")\n",
        "y_train = np.load(f\"{BASE_PATH}/y_train_mc.npy\")\n",
        "y_test  = np.load(f\"{BASE_PATH}/y_test_mc.npy\")\n",
        "\n",
        "print(\"âœ… Data loaded successfully!\")\n",
        "print(f\"X_train: {X_train.shape} | y_train: {y_train.shape}\")\n",
        "print(f\"X_test : {X_test.shape}  | y_test : {y_test.shape}\")\n",
        "\n",
        "# Check data distribution\n",
        "print(\"\\nðŸ“Š Train data distribution:\")\n",
        "train_counter = Counter(y_train)\n",
        "monitored_train = sum(1 for label in y_train if label >= 0)\n",
        "unmonitored_train = sum(1 for label in y_train if label == -1)\n",
        "print(f\"  - Monitored (0~94): {monitored_train} samples\")\n",
        "print(f\"  - Unmonitored (-1): {unmonitored_train} samples\")\n",
        "\n",
        "print(\"\\nðŸ“Š Test data distribution:\")\n",
        "test_counter = Counter(y_test)\n",
        "monitored_test = sum(1 for label in y_test if label >= 0)\n",
        "unmonitored_test = sum(1 for label in y_test if label == -1)\n",
        "print(f\"  - Monitored (0~94): {monitored_test} samples\")\n",
        "print(f\"  - Unmonitored (-1): {unmonitored_test} samples\")\n",
        "\n",
        "print(\"Check for labels:\", np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv4wrvkSNYjb",
        "outputId": "df2b68b0-b781-417f-8bae-c0a96a02bfa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Training Random Forest model for Multi-class Classification...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.0s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Training complete!\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.6min finished\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------\n",
        "# 2. Random Forest Model training\n",
        "# -----------------------------------------------------\n",
        "rf_multi = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    criterion='entropy',\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"ðŸš€ Training Random Forest model for Multi-class Classification...\")\n",
        "rf_multi.fit(X_train, y_train)\n",
        "print(\"\\nâœ… Training complete!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4zmubuLNYjc",
        "outputId": "e7bf9d66-d98f-4563-fbe0-bd7213529fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”® Making predictions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Prediction complete!\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed:    0.6s finished\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------\n",
        "# 3. Prediction\n",
        "# -----------------------------------------------------\n",
        "print(\"ðŸ”® Making predictions...\")\n",
        "y_pred = rf_multi.predict(X_test)\n",
        "y_prob = rf_multi.predict_proba(X_test)  # Probability for each class\n",
        "\n",
        "print(\"âœ… Prediction complete!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmbMWUuvNYjc",
        "outputId": "fb8252f1-d444-41f0-eab2-739e2ef8f956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ðŸ“ˆ OVERALL PERFORMANCE METRICS\n",
            "============================================================\n",
            "ðŸŽ¯ Overall Accuracy: 0.8315\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.75      0.88      0.81       750\n",
            "         0.0       0.89      0.84      0.87        50\n",
            "         1.0       0.95      0.72      0.82        50\n",
            "         2.0       0.96      0.92      0.94        50\n",
            "         3.0       0.89      0.84      0.87        50\n",
            "         4.0       0.89      0.94      0.91        50\n",
            "         5.0       0.84      0.82      0.83        50\n",
            "         6.0       0.87      0.90      0.88        50\n",
            "         7.0       0.84      0.92      0.88        50\n",
            "         8.0       0.90      0.76      0.83        50\n",
            "         9.0       0.85      0.78      0.81        50\n",
            "        10.0       0.95      0.82      0.88        50\n",
            "        11.0       0.95      0.82      0.88        50\n",
            "        12.0       0.89      0.94      0.91        50\n",
            "        13.0       0.79      0.60      0.68        50\n",
            "        14.0       0.66      0.70      0.68        50\n",
            "        15.0       0.76      0.74      0.75        50\n",
            "        16.0       0.97      0.68      0.80        50\n",
            "        17.0       0.75      0.86      0.80        50\n",
            "        18.0       0.96      0.96      0.96        50\n",
            "        19.0       0.77      0.74      0.76        50\n",
            "        20.0       0.93      1.00      0.96        50\n",
            "        21.0       0.87      0.90      0.88        50\n",
            "        22.0       0.80      0.72      0.76        50\n",
            "        23.0       0.86      0.86      0.86        50\n",
            "        24.0       0.65      0.48      0.55        50\n",
            "        25.0       0.82      0.94      0.88        50\n",
            "        26.0       0.83      0.98      0.90        50\n",
            "        27.0       0.92      0.70      0.80        50\n",
            "        28.0       0.92      0.90      0.91        50\n",
            "        29.0       0.83      0.80      0.82        50\n",
            "        30.0       0.73      0.82      0.77        50\n",
            "        31.0       0.88      0.98      0.92        50\n",
            "        32.0       0.74      0.68      0.71        50\n",
            "        33.0       0.91      0.80      0.85        50\n",
            "        34.0       0.81      0.84      0.82        50\n",
            "        35.0       0.92      0.88      0.90        50\n",
            "        36.0       0.98      0.80      0.88        50\n",
            "        37.0       0.91      0.84      0.88        50\n",
            "        38.0       0.81      0.86      0.83        50\n",
            "        39.0       0.83      0.88      0.85        50\n",
            "        40.0       0.77      0.72      0.74        50\n",
            "        41.0       0.94      0.92      0.93        50\n",
            "        42.0       0.78      0.78      0.78        50\n",
            "        43.0       0.98      0.94      0.96        50\n",
            "        44.0       0.91      0.96      0.93        50\n",
            "        45.0       0.74      0.80      0.77        50\n",
            "        46.0       0.92      0.48      0.63        50\n",
            "        47.0       0.82      0.82      0.82        50\n",
            "        48.0       0.95      0.76      0.84        50\n",
            "        49.0       0.82      0.90      0.86        50\n",
            "        50.0       0.87      0.82      0.85        50\n",
            "        51.0       0.83      0.80      0.82        50\n",
            "        52.0       0.84      0.84      0.84        50\n",
            "        53.0       0.84      0.64      0.73        50\n",
            "        54.0       0.85      0.92      0.88        50\n",
            "        55.0       0.81      0.68      0.74        50\n",
            "        56.0       0.96      0.96      0.96        50\n",
            "        57.0       0.89      0.94      0.91        50\n",
            "        58.0       0.94      0.94      0.94        50\n",
            "        59.0       0.96      0.90      0.93        50\n",
            "        60.0       0.90      0.76      0.83        50\n",
            "        61.0       0.78      0.80      0.79        50\n",
            "        62.0       0.88      0.86      0.87        50\n",
            "        63.0       0.74      0.84      0.79        50\n",
            "        64.0       0.84      0.72      0.77        50\n",
            "        65.0       0.79      0.88      0.83        50\n",
            "        66.0       0.80      0.86      0.83        50\n",
            "        67.0       0.88      0.90      0.89        50\n",
            "        68.0       0.77      0.82      0.80        50\n",
            "        69.0       0.85      0.68      0.76        50\n",
            "        70.0       0.92      0.96      0.94        50\n",
            "        71.0       0.83      0.90      0.87        50\n",
            "        72.0       0.89      0.80      0.84        50\n",
            "        73.0       0.86      0.88      0.87        50\n",
            "        74.0       0.78      0.76      0.77        50\n",
            "        75.0       0.98      0.94      0.96        50\n",
            "        76.0       0.91      0.96      0.93        50\n",
            "        77.0       0.70      0.74      0.72        50\n",
            "        78.0       0.80      0.56      0.66        50\n",
            "        79.0       0.80      0.70      0.74        50\n",
            "        80.0       0.89      0.80      0.84        50\n",
            "        81.0       0.93      0.80      0.86        50\n",
            "        82.0       0.83      0.80      0.82        50\n",
            "        83.0       0.82      0.90      0.86        50\n",
            "        84.0       0.80      0.80      0.80        50\n",
            "        85.0       0.88      0.90      0.89        50\n",
            "        86.0       0.84      0.94      0.89        50\n",
            "        87.0       0.82      0.80      0.81        50\n",
            "        88.0       0.85      0.88      0.86        50\n",
            "        89.0       0.75      0.76      0.75        50\n",
            "        90.0       0.80      0.80      0.80        50\n",
            "        91.0       0.84      0.84      0.84        50\n",
            "        92.0       0.80      0.82      0.81        50\n",
            "        93.0       0.83      0.90      0.87        50\n",
            "        94.0       0.71      0.70      0.71        50\n",
            "\n",
            "    accuracy                           0.83      5500\n",
            "   macro avg       0.85      0.82      0.83      5500\n",
            "weighted avg       0.84      0.83      0.83      5500\n",
            "\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------\n",
        "# 4. Overall performance evaluation\n",
        "# -----------------------------------------------------\n",
        "overall_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸ“ˆ OVERALL PERFORMANCE METRICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"ðŸŽ¯ Overall Accuracy: {overall_acc:.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}