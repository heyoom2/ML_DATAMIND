{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk4MsR00vj8U"
      },
      "source": [
        "**In/Out 공통함수**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekPiWD39vjF1"
      },
      "outputs": [],
      "source": [
        "# 추가한 부분!!!!!!\n",
        "def extract_inout_features(packet_sequence):\n",
        "    incoming_count = 0\n",
        "    outgoing_count = 0\n",
        "\n",
        "    for c in packet_sequence:\n",
        "        if c > 0:\n",
        "            outgoing_count += 1\n",
        "        else:\n",
        "            incoming_count += 1\n",
        "\n",
        "    total_packets = len(packet_sequence)\n",
        "    incoming_fraction = incoming_count / total_packets if total_packets > 0 else 0\n",
        "    outgoing_fraction = outgoing_count / total_packets if total_packets > 0 else 0\n",
        "\n",
        "    return incoming_count, outgoing_count, incoming_fraction, outgoing_fraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a7b3a0l2ep4"
      },
      "source": [
        "1. mon_standard.pkl > array code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mfwrTwPtd36",
        "outputId": "b134312c-d5e7-4f4c-ba7e-f141c45ccbd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datafile...\n",
            "Total samples: 19000\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# 추가한 부분!!!!!!\n",
        "def extract_inout_features(packet_sequence):\n",
        "    incoming_count = sum(1 for c in packet_sequence if c < 0)\n",
        "    outgoing_count = sum(1 for c in packet_sequence if c > 0)\n",
        "    total_packets = len(packet_sequence)\n",
        "    incoming_fraction = incoming_count / total_packets if total_packets > 0 else 0\n",
        "    outgoing_fraction = outgoing_count / total_packets if total_packets > 0 else 0\n",
        "    return incoming_count, outgoing_count, incoming_fraction, outgoing_fraction\n",
        "\n",
        "\n",
        "USE_SUBLABEL = False\n",
        "URL_PER_SITE = 10\n",
        "TOTAL_URLS   = 950\n",
        "\n",
        "# Load the pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open(\"/content/mon_standard.pkl\", 'rb') as fi: # Path to mon_standard.pkl in Colab\n",
        "    data = pickle.load(fi)\n",
        "\n",
        "X1 = [] # Array to store instances (timestamps) - 19,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
        "X2 = [] # Array to store instances (direction*size) - size information\n",
        "y = [] # Array to store the site of each instance - 19,000 instances, e.g., [0, 0, 0, 0, 0, 0, ..., 94, 94, 94, 94, 94]\n",
        "features_list = []\n",
        "\n",
        "# Differentiate instances and sites, and store them in the respective x and y arrays\n",
        "# x array (direction*timestamp), y array (site label)\n",
        "for i in range(TOTAL_URLS):\n",
        "    if USE_SUBLABEL:\n",
        "        label = i\n",
        "    else:\n",
        "        label = i // URL_PER_SITE # Calculate which site's URL the current URL being processed belongs to and set that value as the label. Thus, URLs fetched from the same site are labeled identically.\n",
        "    for sample in data[i]:\n",
        "        size_seq = []\n",
        "        time_seq = []\n",
        "        for c in sample:\n",
        "            dr = 1 if c > 0 else -1\n",
        "            time_seq.append(abs(c))\n",
        "            size_seq.append(dr * 512)\n",
        "        X1.append(time_seq)\n",
        "        X2.append(size_seq)\n",
        "        y.append(label)\n",
        "\n",
        "        # 추가한 부분!!!!!!\n",
        "        # Extract in/out features\n",
        "        in_count, out_count, in_frac, out_frac = extract_inout_features(size_seq)\n",
        "        features_list.append([in_count, out_count, in_frac, out_frac])\n",
        "size = len(y)\n",
        "\n",
        "print(f'Total samples: {size}') # Output: 19000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz5mat0w2dJy"
      },
      "source": [
        "2. unmon_standard10.pkl > array code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWfcIOZovSMl",
        "outputId": "397195f4-4d92-43cc-9221-a6f51558f753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datafile...\n",
            "Total samples: 10000\n",
            "10000\n",
            "Unmonitored features shape: (10000, 4)\n",
            "Unmonitored labels shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 추가한 부분!!!!!!\n",
        "def extract_inout_features(packet_sequence):\n",
        "    incoming_count = sum(1 for c in packet_sequence if c < 0)\n",
        "    outgoing_count = sum(1 for c in packet_sequence if c > 0)\n",
        "    total_packets = len(packet_sequence)\n",
        "    incoming_fraction = incoming_count / total_packets if total_packets > 0 else 0\n",
        "    outgoing_fraction = outgoing_count / total_packets if total_packets > 0 else 0\n",
        "    return incoming_count, outgoing_count, incoming_fraction, outgoing_fraction\n",
        "\n",
        "TOTAL_URLS = 10000  # total number in the dataset\n",
        "\n",
        "# Load 10,000 unmon pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open('/content/unmon_standard10.pkl', 'rb') as f:  # Path to unmon_standard10.pkl in Colab\n",
        "    x = pickle.load(f)\n",
        "\n",
        "size = len(x)\n",
        "print(f'Total samples: {size}')\n",
        "\n",
        "X1 = [] # Array to store instances (timestamps) - 10,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
        "X2 = [] # Array to store instances (direction*size) - size information\n",
        "features_list = []\n",
        "\n",
        "for i in range(TOTAL_URLS):\n",
        "    size_seq = []\n",
        "    time_seq = []\n",
        "    for c in x[i]:\n",
        "        dr = 1 if c > 0 else -1\n",
        "        time_seq.append(abs(c))\n",
        "        size_seq.append(dr * 512) # In the pickle file, there is no size information, so the conversion code is set to multiply by 512 uniformly.\n",
        "    X1.append(time_seq)\n",
        "    X2.append(size_seq)\n",
        "\n",
        "    # 추가한 부분!!!!!\n",
        "    # Extract features from size_seq\n",
        "    in_count, out_count, in_frac, out_frac = extract_inout_features(size_seq)\n",
        "    features_list.append([in_count, out_count, in_frac, out_frac])\n",
        "\n",
        "print(len(X1)) # Print the length of X1\n",
        "\n",
        "# Convert to numpy arrays\n",
        "features_unmon = np.array(features_list)\n",
        "labels_unmon = np.full(len(X1), -1)  # Unmonitored label: -1\n",
        "\n",
        "# 추가한 부분!!!!!!\n",
        "print(f'Unmonitored features shape: {features_unmon.shape}')\n",
        "print(f'Unmonitored labels shape: {labels_unmon.shape}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
